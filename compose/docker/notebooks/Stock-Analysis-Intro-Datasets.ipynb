{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Analysis Engine - Extracting Datasets\n",
    "\n",
    "This notebook shows how to extract datasets once they have been collected. Please refer to the [distributed dataset collection tools](https://github.com/AlgoTraders/stock-analysis-engine#distributed-automation-with-docker) for quickly downloading some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Services\n",
    "\n",
    "To develop jupyter notebooks start the [notebook-integration](https://github.com/AlgoTraders/stock-analysis-engine/blob/master/compose/notebook-integration.yml) containers using docker-compose. Here's the command to start it:\n",
    "```\n",
    "./compose/start.sh -j\n",
    "```\n",
    "Verify the containers are running:\n",
    "```\n",
    "docker ps -a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data for this guide was collected using the automated dataset collection:\n",
    "```\n",
    "./compose/start.sh -c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Datasets are in Redis\n",
    "\n",
    "By default the datasets are [automatically archived in S3](http://localhost:9000/minio/pricing/) and cached in Redis. Until S3 extraction is supported, let's confirm the datasets are in Redis before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands assume you have the [redis client installed](https://redis.io/download):\n",
    "\n",
    "```\n",
    "redis-cli\n",
    "127.0.0.1:6379> select 4\n",
    "OK\n",
    "127.0.0.1:6379[4]> keys NFLX_*\n",
    " 1) \"NFLX_2018-10-07_options\"\n",
    " 2) \"NFLX_2018-10-07_tick\"\n",
    " 3) \"NFLX_2018-10-07_pricing\"\n",
    " 4) \"NFLX_2018-10-07_minute\"\n",
    " 5) \"NFLX_2018-10-07\"\n",
    " 6) \"NFLX_2018-10-07_company\"\n",
    " 7) \"NFLX_2018-10-07_daily\"\n",
    " 8) \"NFLX_2018-10-07_news\"\n",
    " 9) \"NFLX_2018-10-07_news1\"\n",
    "10) \"NFLX_2018-10-07_peers\"\n",
    "11) \"NFLX_2018-10-07_dividends\"\n",
    "12) \"NFLX_2018-10-07_stats\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from spylunking.log.setup_logging import build_colorized_logger\n",
    "from analysis_engine.iex.utils import last_close\n",
    "\n",
    "log = build_colorized_logger(name='intro-ds-1', handler_name='jupyter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Ticker and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'NFLX'\n",
    "use_last_close = last_close()\n",
    "last_close_str = use_last_close.strftime('%Y-%m-%d')\n",
    "log.info('Using ticker={} and last close={}'.format(ticker, last_close_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Entire Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis_engine.iex.extract_df_from_redis as extract_utils\n",
    "\n",
    "extract_req = work\n",
    "extract_req['redis_key'] = '{}_minute'.format(work['redis_key'])\n",
    "\n",
    "log.info('extracting - start - ticker={} from redis_key={}'.format(ticker, extract_req['redis_key']))\n",
    "extract_status, minute_df = extract_utils.extract_minute_dataset(work_dict=work)\n",
    "log.info('extracting - done - ticker={} from redis_key={}'.format(ticker, extract_req['redis_key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis_engine.charts as ae_charts\n",
    "from analysis_engine.consts import SUCCESS\n",
    "from analysis_engine.consts import IEX_MINUTE_DATE_FORMAT\n",
    "\n",
    "today_str = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "if extract_status == SUCCESS:\n",
    "    log.info(\n",
    "        'ticker={} creating chart date={}'.format(\n",
    "            ticker,\n",
    "            today_str))\n",
    "    \"\"\"\n",
    "    Plot Pricing with the Volume Overlay:\n",
    "    \"\"\"\n",
    "    image_res = ae_charts.plot_overlay_pricing_and_volume(\n",
    "        log_label='intro-nb-{}'.format(ticker),\n",
    "        ticker=ticker,\n",
    "        date_format=IEX_MINUTE_DATE_FORMAT,\n",
    "        df=minute_df,\n",
    "        show_plot=True)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, work['redis_key']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
