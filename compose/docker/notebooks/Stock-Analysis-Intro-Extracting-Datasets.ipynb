{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting NFLX Datasets\n",
    "\n",
    "This notebook shows how to extract datasets once they have been collected. Please refer to the [distributed dataset collection tools](https://github.com/AlgoTraders/stock-analysis-engine#distributed-automation-with-docker) for quickly downloading some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Services\n",
    "\n",
    "To develop jupyter notebooks start the [notebook-integration](https://github.com/AlgoTraders/stock-analysis-engine/blob/master/compose/notebook-integration.yml) containers using docker-compose. Here's the command to start it:\n",
    "```\n",
    "./compose/start.sh -j\n",
    "```\n",
    "Verify the containers are running:\n",
    "```\n",
    "docker ps -a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample data for this guide was collected using the automated dataset collection:\n",
    "```\n",
    "./compose/start.sh -c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Datasets are in Redis\n",
    "\n",
    "By default the datasets are [automatically archived in S3](http://localhost:9000/minio/pricing/) and cached in Redis. Until S3 extraction is supported, let's confirm the datasets are in Redis before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These commands assume you have the [redis client installed](https://redis.io/download):\n",
    "\n",
    "```\n",
    "redis-cli\n",
    "127.0.0.1:6379> select 4\n",
    "OK\n",
    "127.0.0.1:6379[4]> keys NFLX_*\n",
    " 1) \"NFLX_2018-10-05_tick\"\n",
    " 2) \"NFLX_2018-10-05_news\"\n",
    " 3) \"NFLX_2018-10-05_daily\"\n",
    " 4) \"NFLX_2018-10-05_stats\"\n",
    " 5) \"NFLX_2018-10-05\"\n",
    " 6) \"NFLX_2018-10-05_minute\"\n",
    " 7) \"NFLX_2018-10-05_options\"\n",
    " 8) \"NFLX_2018-10-05_company\"\n",
    " 9) \"NFLX_2018-10-05_dividends\"\n",
    "10) \"NFLX_2018-10-05_pricing\"\n",
    "11) \"NFLX_2018-10-05_peers\"\n",
    "12) \"NFLX_2018-10-05_news1\"\n",
    "127.0.0.1:6379[4]> \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Imports and Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import analysis_engine.charts as ae_charts\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "from analysis_engine.api_requests import get_ds_dict\n",
    "from analysis_engine.consts import SUCCESS\n",
    "from analysis_engine.consts import ppj\n",
    "from analysis_engine.consts import IEX_MINUTE_DATE_FORMAT\n",
    "from analysis_engine.consts import IEX_DAILY_DATE_FORMAT\n",
    "from analysis_engine.consts import IEX_TICK_DATE_FORMAT\n",
    "from analysis_engine.utils import utc_now_str\n",
    "from analysis_engine.utils import get_last_close_str\n",
    "from spylunking.log.setup_logging import build_colorized_logger\n",
    "\n",
    "log_label = 'intro-ds-1'\n",
    "log = build_colorized_logger(name=log_label, handler_name='jupyter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Ticker and Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'NFLX'\n",
    "today_str = utc_now_str()\n",
    "last_close_str = get_last_close_str()\n",
    "\n",
    "log.info('Using ticker={} with last close={}'.format(ticker, last_close_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cache Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dict = get_ds_dict(ticker=ticker, label=log_label)\n",
    "log.info('Cache keys for ticker={} and last close={} cache_dict={}'.format(ticker, last_close_str, ppj(cache_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Minute Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_minute_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, minute_df = extract_minute_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    log.info(\n",
    "        'ticker={} creating chart date={}'.format(\n",
    "            ticker,\n",
    "            today_str))\n",
    "    \"\"\"\n",
    "    Plot Pricing with the Volume Overlay:\n",
    "    \"\"\"\n",
    "    image_res = ae_charts.plot_overlay_pricing_and_volume(\n",
    "        log_label='intro-nb-{}'.format(ticker),\n",
    "        ticker=ticker,\n",
    "        date_format=IEX_MINUTE_DATE_FORMAT,\n",
    "        df=minute_df,\n",
    "        show_plot=True)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['minute']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Tick Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_daily_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, tick_df = extract_daily_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    log.info(\n",
    "        'ticker={} creating chart date={}'.format(\n",
    "            ticker,\n",
    "            today_str))\n",
    "    \"\"\"\n",
    "    Plot Pricing with the Volume Overlay:\n",
    "    \"\"\"\n",
    "    image_res = ae_charts.plot_overlay_pricing_and_volume(\n",
    "        log_label='intro-nb-{}'.format(ticker),\n",
    "        ticker=ticker,\n",
    "        date_format=IEX_TICK_DATE_FORMAT,\n",
    "        df=tick_df,\n",
    "        show_plot=True)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['tick']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Daily Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_daily_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, daily_df = extract_daily_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    log.info(\n",
    "        'ticker={} creating chart date={}'.format(\n",
    "            ticker,\n",
    "            today_str))\n",
    "    \"\"\"\n",
    "    Plot Pricing with the Volume Overlay:\n",
    "    \"\"\"\n",
    "    image_res = ae_charts.plot_overlay_pricing_and_volume(\n",
    "        log_label='intro-nb-{}'.format(ticker),\n",
    "        ticker=ticker,\n",
    "        date_format=IEX_DAILY_DATE_FORMAT,\n",
    "        df=daily_df,\n",
    "        show_plot=True)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['daily']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Stats Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_stats_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, stats_df = extract_stats_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(stats_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['stats']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Peers Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_peers_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, peers_df = extract_peers_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(peers_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['peers']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting News from IEX Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_news_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, news_iex_df = extract_news_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(news_iex_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['news1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Financials Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_financials_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, financials_df = extract_financials_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(financials_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['financials']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Earnings Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_earnings_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, earnings_df = extract_earnings_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(earnings_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['earnings']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Dividends Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_dividends_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, dividends_df = extract_dividends_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(dividends_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['dividends']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Company Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.iex.extract_df_from_redis import extract_company_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, company_df = extract_company_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(company_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['company']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Option Calls Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.yahoo.extract_df_from_redis import extract_option_calls_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, option_calls_df = extract_option_calls_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(option_calls_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['options']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Option Puts Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.yahoo.extract_df_from_redis import extract_option_puts_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, option_puts_df = extract_option_puts_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(option_puts_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['options']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Pricing from Yahoo Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.yahoo.extract_df_from_redis import extract_pricing_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, pricing_df = extract_pricing_dataset(cache_dict)\n",
    "log.info('extracting - done - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(pricing_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['pricing']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting News from Yahoo Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_engine.yahoo.extract_df_from_redis import extract_yahoo_news_dataset\n",
    "\n",
    "log.info('extracting - start - ticker={}'.format(ticker))\n",
    "extract_status, news_yahoo_df = extract_yahoo_news_dataset(cache_dict)\n",
    "log.info('extracting - end - ticker={}'.format(ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extract_status == SUCCESS:\n",
    "    display(news_yahoo_df)\n",
    "else:\n",
    "    log.error('ticker={} - did not extract a dataset from redis_key={}'.format(ticker, cache_dict['news']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
